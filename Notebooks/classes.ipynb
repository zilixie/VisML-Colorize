{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaBE9Y3C2qSa",
        "colab_type": "text"
      },
      "source": [
        "# **Train & Test Transform**\n",
        "Resacle and Random Crop the image for generalization. <br/>\n",
        "For testing transform, Fix crop position to get consistent input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQTuVZrI2nUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Scale(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Scale(256),\n",
        "    transforms.CenterCrop(224)\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzeQfcnW3IAn",
        "colab_type": "text"
      },
      "source": [
        "# **Attribute Dict**\n",
        "Use arg dict as a compact input to training/testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V4DivdS2jtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "from skimage.color import rgb2lab\n",
        "from skimage.transform import resize\n",
        "from skimage import color\n",
        "from PIL import Image\n",
        "\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import os\n",
        "import sklearn.neighbors as nbrs\n",
        "\n",
        "class AttrDict(dict):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(AttrDict, self).__init__(*args, **kwargs)\n",
        "        self.__dict__ = self\n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1f7pVKp79iU",
        "colab_type": "text"
      },
      "source": [
        "# **Color Rebalancing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIErVExh782i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ColorRebal(object):\n",
        "    def __init__(self, gamma):\n",
        "        self.gamma = gamma\n",
        "        self.prior_probs = np.load('./resources/probs.npy')\n",
        "        self.uni_probs = np.ones(self.prior_probs.shape)\n",
        "        self.uni_probs = self.uni_probs / np.sum(self.uni_probs)\n",
        "\n",
        "        self.prior_factor = ((1 - self.gamma) * self.prior_probs + self.gamma * self.uni_probs) ** (-1)\n",
        "        self.prior_factor = self.prior_factor / np.sum(self.prior_probs * self.prior_factor)  # re-normalize\n",
        "        np.save('./resources/rebal_probs.npy', self.prior_factor)\n",
        "\n",
        "    def forward(self, max_encode):\n",
        "        corr_factor = self.prior_factor[max_encode]\n",
        "        return np.expand_dims(corr_factor, axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DexTOkon7PYX",
        "colab_type": "text"
      },
      "source": [
        "# **Encode Layer**\n",
        "Encode image from lab color space to corresponding color class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTvWOdtc7ObI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encode():\n",
        "    def __init__(self, NN, sigma, batch_size, km_filepath):\n",
        "        self.cc = np.load(km_filepath) # pts.npy (199,2)\n",
        "        self.num_colors = self.cc.shape[0] # 199\n",
        "        self.NN = int(NN)\n",
        "        self.sigma = sigma\n",
        "        self.nbrs = nbrs.NearestNeighbors(n_neighbors=NN, algorithm='ball_tree').fit(self.cc)\n",
        "        self.encode_vec = np.zeros((56 * 56 * batch_size, self.num_colors))\n",
        "\n",
        "    def encode(self, pts_origin):\n",
        "        flat_pts = flatten(pts_origin)\n",
        "        self.encode_vec[...] = 0 # (125440, 199)\n",
        "        (d, indices) = self.nbrs.kneighbors(flat_pts)\n",
        "\n",
        "        # print(dists.shape) # dist to 32 nearest bins\n",
        "        # print(inds[0])  # 32 nearest bins\n",
        "\n",
        "        weights = np.exp(-d ** 2 / (2 * self.sigma ** 2))\n",
        "        weights = weights / np.expand_dims(np.sum(weights, axis=1), axis=-1) # softmax of gaussian (125440, 32)\n",
        "        pts_ind = np.expand_dims(np.arange(0, flat_pts.shape[0], dtype='int'), axis=-1)\n",
        "        self.encode_vec[pts_ind, indices] = weights\n",
        "\n",
        "        encode_origin_shape = restore(self.encode_vec, pts_origin)\n",
        "        return encode_origin_shape\n",
        "\n",
        "class EncodeMax(object):\n",
        "    def __init__(self, NN, sigma, batch_size):\n",
        "        self.NN = NN\n",
        "        self.sigma = sigma\n",
        "        self.nnenc = Encode(self.NN, self.sigma, batch_size, km_filepath='./resources/pts.npy')\n",
        "\n",
        "    def forward(self, x):\n",
        "        encode = self.nnenc.encode(x) # (40, 199, 56, 56)\n",
        "        max_encode = np.argmax(encode,axis=1).astype(np.int32) # (40, 56, 56)\n",
        "        return encode, max_encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUnr3KWm3rK4",
        "colab_type": "text"
      },
      "source": [
        "# **GrayScale Mask**\n",
        "Screen the black and white images by void their contribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uLQHKyB3uiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GrayScaleMask(object):\n",
        "    def forward(self, bottom):\n",
        "        bottom = bottom.numpy()\n",
        "        s1 = (np.abs(bottom) > 5).astype('float')\n",
        "        s2 = np.sum(s1, axis=1)\n",
        "        s3 = np.sum(s2, axis=1)\n",
        "        s4 = np.sum(s3, axis=1)\n",
        "        out = (s4 > 0)[:, np.newaxis, np.newaxis, np.newaxis].astype('float')\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}